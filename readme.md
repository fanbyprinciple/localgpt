# Chat locally

has issues like we have o install the docker container first then interact

# trying Groqchatbot

https://github.com/InsightEdge01/GroqPDFFastChatbot

ollama pull nomic-*

streamlit run app.py

# Medical chatbot

https://www.youtube.com/watch?v=kXuHxI5ZcG0

has an issue with pwd command can onl run in linux

# instaling localgpt

https://www.youtube.com/watch?v=9u5rcRHqrrQ&t=15s

using python nvironement 3.8

# THe amazing worl of fineuning llama
https://github.com/AIAnytime/Chat-with-PDF-Chatbot

![](2024-04-15-01-02-08.png)

first glimmer of success

# quantisation

Quantisation is a technique to reduce the computational and memory cost of running inference by representing the weights and activations with low precision data types like 8 bit integer instead of the usual 32 bit floating point

reducing bits mean less storage and less energy

https://huggingface.co/blog/os-llms


# trying on RAG

https://github.com/AllAboutAI-YT/easy-local-rag?tab=readme-ov-file

first install pytorch cpuonly

next error was regarding ollamma we need to pull the model first

this needed to be done yesterday.

